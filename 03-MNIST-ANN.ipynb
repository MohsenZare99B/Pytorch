{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNwCZZDuNCwoBlozjc3bD6q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"1R6lwhno2V8k","executionInfo":{"status":"ok","timestamp":1669819880904,"user_tz":-210,"elapsed":4,"user":{"displayName":"Mohsen Zare","userId":"17637179186040968832"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["train_dataset = torchvision.datasets.MNIST(\n","    root='.',\n","    train=True,\n","    transform=transforms.ToTensor(),\n","    download=True\n",")"],"metadata":{"id":"tZVAspRKBKG0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset.data.max()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N0W-U3R-Bl-k","executionInfo":{"status":"ok","timestamp":1669820002097,"user_tz":-210,"elapsed":7,"user":{"displayName":"Mohsen Zare","userId":"17637179186040968832"}},"outputId":"6b847f8f-36bf-48e1-e2bf-9d69ea4709b4"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(255, dtype=torch.uint8)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["train_dataset.data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xk_wXy6kBvxx","executionInfo":{"status":"ok","timestamp":1669820024865,"user_tz":-210,"elapsed":5,"user":{"displayName":"Mohsen Zare","userId":"17637179186040968832"}},"outputId":"bd0ee11a-132b-4b90-dc08-d04fd9756b59"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([60000, 28, 28])"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["test_dataset = torchvision.datasets.MNIST(\n","    root='.',\n","    train=False,\n","    transform=transforms.ToTensor(),\n","    download=True\n",")\n","\n","test_dataset.data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3tlb7k9iB3-y","executionInfo":{"status":"ok","timestamp":1669820110090,"user_tz":-210,"elapsed":6,"user":{"displayName":"Mohsen Zare","userId":"17637179186040968832"}},"outputId":"a6959949-dee9-4825-bcf4-499bffb34a31"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([10000, 28, 28])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["model = nn.Sequential(\n","    nn.Linear(784, 128),\n","    nn.ReLU(),\n","    nn.Linear(128, 10)\n",")"],"metadata":{"id":"OtguYK9hCNE_","executionInfo":{"status":"ok","timestamp":1669820199216,"user_tz":-210,"elapsed":5,"user":{"displayName":"Mohsen Zare","userId":"17637179186040968832"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ql2mfYWjCi6V","executionInfo":{"status":"ok","timestamp":1669820288648,"user_tz":-210,"elapsed":504,"user":{"displayName":"Mohsen Zare","userId":"17637179186040968832"}},"outputId":"de993f62-0813-4e83-e9eb-b7ba7bf5082d"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]},{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Linear(in_features=784, out_features=128, bias=True)\n","  (1): ReLU()\n","  (2): Linear(in_features=128, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters())"],"metadata":{"id":"iYraykIJC1c0","executionInfo":{"status":"ok","timestamp":1669820393952,"user_tz":-210,"elapsed":2,"user":{"displayName":"Mohsen Zare","userId":"17637179186040968832"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["batch_size = 128\n","\n","#DataLoader maps values from (0, 255) to (0, 1)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True)\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False)"],"metadata":{"id":"q1_2MM1tDSWr","executionInfo":{"status":"ok","timestamp":1669820526218,"user_tz":-210,"elapsed":5,"user":{"displayName":"Mohsen Zare","userId":"17637179186040968832"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["n_epochs = 10\n","\n","train_losses = np.zeros(n_epochs)\n","test_losses = np.zeros(n_epochs)\n","\n","for it in range(n_epochs):\n","  train_loss, test_loss = [], []\n","  for inputs, targets in train_loader:\n","    inputs, targets = inputs.to(device), targets.to(device)\n","    inputs.view(-1, 784) # Reshape the input\n","    optimizer.zero_grad()\n","    outputs = model(inputs)\n","    loss = criterion(outputs, targets)\n","    loss.backward()\n","    optimizer.step()\n","\n","  for inputs, targets in test_loader:\n","    inputs, targets = inputs.to(device), targets.to(device)\n","    inputs.view(-1, 784)\n","    outputs = model(inputs)\n","    loss = criterion(outputs, targets)\n","    test_loss.append(loss.item())\n","\n","  train_losses[it] = np.mean(train_loss)\n","  test_losses[it] = np.mean(test_loss)\n","\n","  print(f'Epoch {it + 1}/{n_epochs}, Train loss:{train_losses[it]:.4}, Test loss:{test_losses[it]:.4}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"id":"OBYzqc9cDynU","executionInfo":{"status":"error","timestamp":1669821408404,"user_tz":-210,"elapsed":566,"user":{"displayName":"Mohsen Zare","userId":"17637179186040968832"}},"outputId":"687457ad-de19-45df-bf97-50e9a64a7a09"},"execution_count":15,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-c04cbb260337>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Reshape the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3584x28 and 784x128)"]}]},{"cell_type":"code","source":[],"metadata":{"id":"W7Q6zvLMEUM-"},"execution_count":null,"outputs":[]}]}